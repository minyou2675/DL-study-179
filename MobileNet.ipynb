{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPIHUh+gPzZJ69a0YDzOjja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minyou2675/DL-study-179/blob/main/MobileNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B51wjDwGwV5K",
        "outputId": "267a30d2-e641-41f0-e058-03055c73a283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1024, 1, 1])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             896\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "              ReLU-3         [-1, 32, 112, 112]               0\n",
            "       BasicConv2d-4         [-1, 32, 112, 112]               0\n",
            "            Conv2d-5         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-6         [-1, 32, 112, 112]              64\n",
            "             ReLU6-7         [-1, 32, 112, 112]               0\n",
            "            Conv2d-8         [-1, 64, 112, 112]           2,048\n",
            "       BatchNorm2d-9         [-1, 64, 112, 112]             128\n",
            "            ReLU6-10         [-1, 64, 112, 112]               0\n",
            "          MBblock-11         [-1, 64, 112, 112]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]             576\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "            ReLU6-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15          [-1, 128, 56, 56]           8,192\n",
            "      BatchNorm2d-16          [-1, 128, 56, 56]             256\n",
            "            ReLU6-17          [-1, 128, 56, 56]               0\n",
            "          MBblock-18          [-1, 128, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 56, 56]           1,152\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "            ReLU6-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]          16,384\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "            ReLU6-24          [-1, 128, 56, 56]               0\n",
            "          MBblock-25          [-1, 128, 56, 56]               0\n",
            "           Conv2d-26          [-1, 128, 28, 28]           1,152\n",
            "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
            "            ReLU6-28          [-1, 128, 28, 28]               0\n",
            "           Conv2d-29          [-1, 256, 28, 28]          32,768\n",
            "      BatchNorm2d-30          [-1, 256, 28, 28]             512\n",
            "            ReLU6-31          [-1, 256, 28, 28]               0\n",
            "          MBblock-32          [-1, 256, 28, 28]               0\n",
            "           Conv2d-33          [-1, 256, 28, 28]           2,304\n",
            "      BatchNorm2d-34          [-1, 256, 28, 28]             512\n",
            "            ReLU6-35          [-1, 256, 28, 28]               0\n",
            "           Conv2d-36          [-1, 256, 28, 28]          65,536\n",
            "      BatchNorm2d-37          [-1, 256, 28, 28]             512\n",
            "            ReLU6-38          [-1, 256, 28, 28]               0\n",
            "          MBblock-39          [-1, 256, 28, 28]               0\n",
            "           Conv2d-40          [-1, 256, 14, 14]           2,304\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "            ReLU6-42          [-1, 256, 14, 14]               0\n",
            "           Conv2d-43          [-1, 512, 14, 14]         131,072\n",
            "      BatchNorm2d-44          [-1, 512, 14, 14]           1,024\n",
            "            ReLU6-45          [-1, 512, 14, 14]               0\n",
            "          MBblock-46          [-1, 512, 14, 14]               0\n",
            "           Conv2d-47          [-1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-48          [-1, 512, 14, 14]           1,024\n",
            "            ReLU6-49          [-1, 512, 14, 14]               0\n",
            "           Conv2d-50          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-51          [-1, 512, 14, 14]           1,024\n",
            "            ReLU6-52          [-1, 512, 14, 14]               0\n",
            "          MBblock-53          [-1, 512, 14, 14]               0\n",
            "           Conv2d-54          [-1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-55          [-1, 512, 14, 14]           1,024\n",
            "            ReLU6-56          [-1, 512, 14, 14]               0\n",
            "           Conv2d-57          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-58          [-1, 512, 14, 14]           1,024\n",
            "            ReLU6-59          [-1, 512, 14, 14]               0\n",
            "          MBblock-60          [-1, 512, 14, 14]               0\n",
            "           Conv2d-61          [-1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-62          [-1, 512, 14, 14]           1,024\n",
            "            ReLU6-63          [-1, 512, 14, 14]               0\n",
            "           Conv2d-64          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-65          [-1, 512, 14, 14]           1,024\n",
            "            ReLU6-66          [-1, 512, 14, 14]               0\n",
            "          MBblock-67          [-1, 512, 14, 14]               0\n",
            "           Conv2d-68          [-1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-69          [-1, 512, 14, 14]           1,024\n",
            "            ReLU6-70          [-1, 512, 14, 14]               0\n",
            "           Conv2d-71          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-72          [-1, 512, 14, 14]           1,024\n",
            "            ReLU6-73          [-1, 512, 14, 14]               0\n",
            "          MBblock-74          [-1, 512, 14, 14]               0\n",
            "           Conv2d-75          [-1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-76          [-1, 512, 14, 14]           1,024\n",
            "            ReLU6-77          [-1, 512, 14, 14]               0\n",
            "           Conv2d-78          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-79          [-1, 512, 14, 14]           1,024\n",
            "            ReLU6-80          [-1, 512, 14, 14]               0\n",
            "          MBblock-81          [-1, 512, 14, 14]               0\n",
            "           Conv2d-82            [-1, 512, 7, 7]           4,608\n",
            "      BatchNorm2d-83            [-1, 512, 7, 7]           1,024\n",
            "            ReLU6-84            [-1, 512, 7, 7]               0\n",
            "           Conv2d-85           [-1, 1024, 7, 7]         524,288\n",
            "      BatchNorm2d-86           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU6-87           [-1, 1024, 7, 7]               0\n",
            "          MBblock-88           [-1, 1024, 7, 7]               0\n",
            "           Conv2d-89           [-1, 1024, 7, 7]           9,216\n",
            "      BatchNorm2d-90           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU6-91           [-1, 1024, 7, 7]               0\n",
            "           Conv2d-92           [-1, 1024, 7, 7]       1,048,576\n",
            "      BatchNorm2d-93           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU6-94           [-1, 1024, 7, 7]               0\n",
            "          MBblock-95           [-1, 1024, 7, 7]               0\n",
            "        AvgPool2d-96           [-1, 1024, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 3,207,008\n",
            "Trainable params: 3,207,008\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 139.16\n",
            "Params size (MB): 12.23\n",
            "Estimated Total Size (MB): 151.97\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "#일반적인 Convolution layer에서 연산량은 해상도x커널크기x입출력채널개수\n",
        "\n",
        "class MBblock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride = 1):\n",
        "    super().__init__()\n",
        "    #mobile block은 depthwise,pointwise -> batch최적화->relu 함수가 연속됨\n",
        "    self.depthwise = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, in_channels, 3, stride = stride, padding =1,\n",
        "                  groups = in_channels, bias = False),\n",
        "                  nn.BatchNorm2d(in_channels),\n",
        "                  nn.ReLU6(),\n",
        "    ) #depth wise는 입력 해상도 x 채널 수 x 중간 featuremap 해상도\n",
        "    #depthwise는 공간에 대한 convolution뿐만 아니라 채널에 대한 convolution을 통해\n",
        "    #채널 압축\n",
        "    self.pointwise = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 1, stride=1 , padding =0,\n",
        "                  bias = False),\n",
        "                  nn.BatchNorm2d(out_channels),\n",
        "                  nn.ReLU6()\n",
        "    ) #point wise의 연산값은 입출력 채널수 x 최종feature map 해상도\n",
        "      #point wise는 공간에 대한 convolution 진행 x 채널에 대한 convolution 함\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.depthwise(x)\n",
        "    x = self.pointwise(x)\n",
        "    return x\n",
        "#논문에 따르면, feature map에 채널 수와 커널 크기에 의해 연산량은 결정된다.\n",
        "class BasicConv2d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return x\n",
        "\n",
        "class MobileNet(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            BasicConv2d(3, 32, 3, stride = 2, padding = 1),\n",
        "            MBblock(32, 64),\n",
        "            MBblock(64, 128, 2),\n",
        "            MBblock(128, 128),\n",
        "            MBblock(128, 256, 2),\n",
        "            MBblock(256, 256),\n",
        "            MBblock(256, 512, 2),\n",
        "            *[MBblock(512,512) for _ in range(5)],\n",
        "            MBblock(512, 1024, 2),\n",
        "            MBblock(1024, 1024),\n",
        "            nn.AvgPool2d(7),\n",
        "            \n",
        "          \n",
        "\n",
        "\n",
        "        )\n",
        "        self.fc = nn.Linear(1024,1000)\n",
        "    \n",
        "        # TODO : Implement Network\n",
        "        ## Sample Convolution, delete this\n",
        "        \n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO : Implement Network\n",
        "        ## Sample Convolution, delete this\n",
        "        x = self.model(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')    \n",
        "    \n",
        "    batch_size = 4\n",
        "    input = torch.randn((batch_size, 3, 224, 224))\n",
        "    model = MobileNet()\n",
        "    output = model(input)\n",
        "    \n",
        "    print(output.shape)\n",
        "    \n",
        "    model.to(device)\n",
        "    summary(model, (3, 224, 224))"
      ]
    }
  ]
}